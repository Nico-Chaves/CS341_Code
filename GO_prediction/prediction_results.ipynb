{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import GO_utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene2go_file_path = '../data/gene2go.txt' # If file doesn't exist, then run gene2go = download_ncbi_associations()\n",
    "rpkm_file_path = '../../CS341_Data/transcript_rpkm_in_go_nonzero_exp.txt'\n",
    "gene_count_file_path = '../data/supp_GO_term_gene_counts.txt'\n",
    "biomart_file_path = '../data/biomart_ensembl_to_entrez.txt'  \n",
    "sample_tissue_path = '../data/sampleID_tissue.txt'\n",
    "obo_file_path = '../data/go-basic.obo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Gene Annotations for all GO terms in Supplementary File (include the GO descendant terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16439 GO terms associated with human NCBI Entrez GeneIDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load obo file ../data/go-basic.obo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/go-basic.obo: format-version(1.2) data-version(releases/2016-04-27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46518 nodes imported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top GO terms\n",
      "GO:0007166   2018\n",
      "GO:0007186   1128\n",
      "GO:0051960   741\n",
      "GO:0050767   659\n",
      "GO:0007167   652\n",
      "GO:0045664   549\n",
      "GO:0007169   483\n",
      "GO:0019221   449\n",
      "GO:0051962   432\n",
      "GO:0002694   425\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "GO_terms = GO_utils.get_go_terms_descendants(biomart_file_path, gene2go_file_path, gene_count_file_path, obo_file_path, ev_codes=None)\n",
    "GO_terms = GO_utils.sort_go_terms(GO_terms)\n",
    "print 'Top GO terms'\n",
    "for t in GO_terms[0:10]:\n",
    "    print t.id, ' ', len(t.genes)\n",
    "\n",
    "term = GO_terms[300]\n",
    "print len(term.genes)\n",
    "ensembl_ids = term.genes\n",
    "ens_ids_dict = {}\n",
    "for id in ensembl_ids:\n",
    "    ens_ids_dict[id] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Pass Through Dataset: Obtain positive training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pass 1 (inserting positive examples), gene feature matrix has dimension:  (50, 8555)\n",
      "num pos examples:  50\n"
     ]
    }
   ],
   "source": [
    "NUM_FEATURES = 8555\n",
    "gene_features, positive_example_rows, gene_ids_ordered, num_transcripts = \\\n",
    "        GO_utils.get_positive_examples(rpkm_file_path, ens_ids_dict, NUM_FEATURES)\n",
    "\n",
    "print 'After pass 1 (inserting positive examples), gene feature matrix has dimension: ', gene_features.shape\n",
    "num_positive_examples = len(positive_example_rows)\n",
    "num_negative_examples = num_positive_examples\n",
    "num_examples = num_positive_examples + num_negative_examples\n",
    "print 'num pos examples: ', num_positive_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Pass through dataset: Obtain an equal number of negative training exmaples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pass 2 (inserting negative examples), gene feature matrix has dimension:  (100, 8555)\n"
     ]
    }
   ],
   "source": [
    "neg_rows = utils.rand_sample_exclude(range(0, num_transcripts), num_negative_examples, exclude=positive_example_rows)\n",
    "\n",
    "gene_features_neg, gene_ids_ordered_neg = \\\n",
    "    GO_utils.get_negative_examples(rpkm_file_path, neg_rows, NUM_FEATURES)\n",
    "gene_features = np.append(gene_features, gene_features_neg, axis=0)\n",
    "gene_ids_ordered += gene_ids_ordered_neg\n",
    "\n",
    "print 'After pass 2 (inserting negative examples), gene feature matrix has dimension: ', gene_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Binary Labels to the Data and split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num examples:  100\n",
      "Dimensionality of training set:  (70, 8555)\n",
      "Dimensionality of test set:  (30, 8555)\n",
      "Obtained training & testing data\n"
     ]
    }
   ],
   "source": [
    "# Vector of labels for each example\n",
    "labels = num_positive_examples * [1] + num_negative_examples * [0]\n",
    "\n",
    "train, test = utils.split_data(gene_features, labels, gene_ids_ordered, train_set_size=0.7)\n",
    "print 'Obtained training & testing data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression With 10-Fold CV, L2 Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Cross-Validated Logistic Regression\n",
      "--------------------\n",
      "Root Mean Square Error:  0.48304589154\n",
      "ROC AUC Score:  0.772321428571\n",
      "False positive rate:  0.166666666667\n",
      "False negative rate:  0.0666666666667\n",
      "Norm: l1, # of Folds: 10\n",
      "Best cost (after inverting to obtain true cost):  [ 78.47599704]\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10   # number of folds to use for cross-validation\n",
    "loss_fxn = 'l2'  # Loss function to use. Must be either 'l1' or 'l2'\n",
    "costs = np.logspace(-4, 4, 20)  # 10^(-arg1) to 10^arg2 in arg3 logarithmic steps\n",
    "logreg_cv_L2 = linear_model.LogisticRegressionCV(Cs=costs, cv=num_folds, penalty=loss_fxn, tol=0.0001)\n",
    "logreg_cv_L2.fit(train.gene_features, train.labels)\n",
    "best_c = logreg_cv_L2.C_\n",
    "pred_lr_cv_L2 = logreg_cv_L2.predict(test.gene_features)\n",
    "utils.print_prediction_results('Cross-Validated Logistic Regression', test.labels, pred_lr_cv_L2,\n",
    "                               other_info='Norm: ' + loss_function + ', # of Folds: ' + str(num_folds))\n",
    "print 'Best cost (after inverting to obtain true cost): ', 1.0 / best_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression With 3-Fold CV, L1 Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Cross-Validated Logistic Regression\n",
      "--------------------\n",
      "ROC AUC Score:  0.599547511312\n",
      "False positive rate:  0.25\n",
      "False negative rate:  0.5\n",
      "Norm: l1, # of Folds: 10\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "num_folds = 10   # number of folds to use for cross-validation\n",
    "loss_function = 'l1'  # Loss function to use. Must be either 'l1' or 'l2'\n",
    "costs = np.logspace(-4, 4, 20)  # 10^(-start) to 10^stop in 10 logarithmic steps\n",
    "logreg_cv_L1 = linear_model.LogisticRegressionCV(Cs=costs, cv=num_folds, penalty=loss_function, solver='liblinear', tol=0.0001)\n",
    "logreg_cv_L1.fit(train.gene_features, train.labels)\n",
    "best_c = logreg_cv_L1.C_\n",
    "pred_lr_cv_L1 = logreg_cv_L1.predict(test.gene_features)\n",
    "utils.print_prediction_results('Cross-Validated Logistic Regression', test.labels, pred_lr_cv_L1, \n",
    "                         other_info='Norm: ' + loss_function + ', # of Folds: ' + str(num_folds))\n",
    "print 'Best cost (after inverting to obtain true cost): ', 1.0 / best_c\n",
    "\n",
    "# Save results\n",
    "out_fname = '../data/result_logreg_' + term.id + '.txt'\n",
    "save_prediction_results(out_fname, term.id, 'Logistic Regresion with L1 Penalty', \n",
    "                              test, pred_lr_cv_L1, num_folds, \n",
    "                              tissue_set=None, best_cost=best_c)\n",
    "                              '''\n",
    "\n",
    "print_prediction_results('Cross-Validated Logistic Regression', test.labels, pred_lr_cv_L1, \n",
    "                         other_info='Norm: ' + loss_function + ', # of Folds: ' + str(num_folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Split training data into train and dev\n",
    "#train_cv , dev = utils.split_data(train.gene_features, train.labels, train.gene_ids_ordered, train_set_size=0.7)\n",
    "\n",
    "svc = SVC(kernel='rbf')\n",
    "Cs = np.logspace(-6, -1, 10)\n",
    "clf = GridSearchCV(estimator=svc, param_grid=dict(C=Cs),n_jobs=-1)    \n",
    "clf.fit(train.gene_features, train.labels)\n",
    "print 'Best score: ', clf.best_score_\n",
    "best_C = clf.best_estimator_.C\n",
    "print 'Best C: ', best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', C=best_C)\n",
    "clf.fit(train.gene_features, train.labels)\n",
    "pred_svm = clf.predict(test.gene_features)\n",
    "utils.print_prediction_results('SVM', test.labels, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in GO_terms[0:100]:\n",
    "    print t.id, ' ', len(t.genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-04   7.74263683e-04   5.99484250e-03   4.64158883e-02\n",
      "   3.59381366e-01   2.78255940e+00   2.15443469e+01   1.66810054e+02\n",
      "   1.29154967e+03   1.00000000e+04]\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "costs = np.logspace(-4, 4, 10)\n",
    "print costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'printhi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-6f0116aec95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinthi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'printhi'"
     ]
    }
   ],
   "source": [
    "utils.printhi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_prediction_results(fname, GO_id, model, test_data, preds, n_folds=None,\n",
    "                            tissue_set=None, best_cost=None, other_info=None):\n",
    "    \"\"\"\n",
    "    Save results of prediction for a given GO term to a text file.\n",
    "\n",
    "    :param fname: Name of output file\n",
    "    :param GO_id: ID of the GO term\n",
    "    :param model: Type of model used (e.g. \"Logistic Regression with L1 Norm\")\n",
    "    :param test_data: GeneData object containing test data\n",
    "    :param preds: Binary predictions for test data\n",
    "    :param n_folds: # of folds used for cross-validation\n",
    "    :param tissue_set: Set of tissues used. If no option is specified, it's assumed that all tissues were used\n",
    "    :param best_cost: If applicable, the best cost parameter (as determined by cross-validation)\n",
    "    :param other_info: Other info to store in header of output file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    out_file = open(fname, 'w')\n",
    "    out_file.write('# Prediction results for GO term: ' + GO_id + '\\n')\n",
    "    out_file.write('# Model used: ' + model + '\\n')\n",
    "    auc_score = roc_auc_score(test_data.labels, preds)\n",
    "\n",
    "    print 'auc: ', auc_score\n",
    "\n",
    "    out_file.write('# ROC AUC Score: ' + str(auc_score) + '\\n')\n",
    "    if tissue_set:\n",
    "        out_file.write('# Tissues used: ' + tissue_set + '\\n')\n",
    "    else:\n",
    "        out_file.write('# All tissues were included\\n')\n",
    "    if n_folds:\n",
    "        out_file.write('# Number of folds used for cross-validation: ' + str(n_folds) + '\\n')\n",
    "    if best_cost:\n",
    "        out_file.write('# Best cost parameter (determined by CV): ' + str(best_cost) + '\\n')\n",
    "    if other_info:\n",
    "        out_file.write('# ' + other_info + '\\n')\n",
    "\n",
    "    # Writ out the predictions\n",
    "    out_file.write('# Gene ID\\tLabel\\tPrediction\\n')\n",
    "    for id,label,pred in zip(test_data.gene_ids_ordered, test_data.labels, preds):\n",
    "        out_file.write(id + '\\t' + str(label) + '\\t' + str(pred) + '\\n')\n",
    "\n",
    "    out_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
